Jitting Chamfer 3D
Loaded JIT 3D CUDA chamfer distance
Loaded JIT 3D CUDA emd
Jitting Chamfer 3D
Loaded JIT 3D CUDA chamfer distance
Jitting Chamfer 3D
Loaded JIT 3D CUDA chamfer distance
Jitting Chamfer 3D
Loaded JIT 3D CUDA chamfer distance
[2022-09-15 15:18:01,331 INFO train_PT-2.py line 205 1877698] arch: pointtransformer_seg_repro
base_lr: 0.001
batch_size: 16
batch_size_test: 4
batch_size_val: 4
block_size: 1.5
classes: 21
data_name: scannet
data_root: dataset/scannet
dist_backend: nccl
dist_url: tcp://localhost:60667
distributed: True
epochs: 50
eval_freq: 1
evaluate: False
fea_dim: 6
ignore_label: 255
loop: 15
manual_seed: 7777
model_path: None
momentum: 0.9
multiplier: 0.1
multiprocessing_distributed: True
names_path: data/s3dis/s3dis_names.txt
ngpus_per_node: 4
num_point: 8192
print_freq: 10
rank: 0
resume: None
sample_rate: 1.0
save_folder: None
save_freq: 1
save_path: exp/scannet/baseline
split: val
start_epoch: 0
step_epoch: 30
stride_rate: 0.5
sync_bn: False
test_gpu: [0]
test_list: dataset/s3dis/list/val5.txt
test_list_full: dataset/s3dis/list/val5_full.txt
test_workers: 4
train_gpu: [4, 5, 6, 7]
use_xyz: True
voxel_max: 80000
voxel_size: 0.04
weight: None
weight_decay: 0.0001
workers: 1
world_size: 4
[2022-09-15 15:18:01,332 INFO train_PT-2.py line 206 1877698] => creating model ...
[2022-09-15 15:18:01,332 INFO train_PT-2.py line 207 1877698] Classes: 21
[2022-09-15 15:18:01,332 INFO train_PT-2.py line 208 1877698] PointTransformerSeg(
  (PT_model): PointTransformer_model(
    (enc1): Sequential(
      (0): TransitionDown(
        (linear): Linear(in_features=6, out_features=32, bias=False)
        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): PointTransformerBlock(
        (linear1): Linear(in_features=32, out_features=32, bias=False)
        (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=32, out_features=32, bias=True)
          (linear_k): Linear(in_features=32, out_features=32, bias=True)
          (linear_v): Linear(in_features=32, out_features=32, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=32, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=32, out_features=4, bias=True)
            (3): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=4, out_features=4, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=32, out_features=32, bias=False)
        (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (enc2): Sequential(
      (0): TransitionDown(
        (linear): Linear(in_features=35, out_features=64, bias=False)
        (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): PointTransformerBlock(
        (linear1): Linear(in_features=64, out_features=64, bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=64, out_features=64, bias=True)
          (linear_k): Linear(in_features=64, out_features=64, bias=True)
          (linear_v): Linear(in_features=64, out_features=64, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=64, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=64, out_features=8, bias=True)
            (3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=8, out_features=8, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=64, out_features=64, bias=False)
        (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): PointTransformerBlock(
        (linear1): Linear(in_features=64, out_features=64, bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=64, out_features=64, bias=True)
          (linear_k): Linear(in_features=64, out_features=64, bias=True)
          (linear_v): Linear(in_features=64, out_features=64, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=64, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=64, out_features=8, bias=True)
            (3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=8, out_features=8, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=64, out_features=64, bias=False)
        (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (enc3): Sequential(
      (0): TransitionDown(
        (linear): Linear(in_features=67, out_features=128, bias=False)
        (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): PointTransformerBlock(
        (linear1): Linear(in_features=128, out_features=128, bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=128, out_features=128, bias=True)
          (linear_k): Linear(in_features=128, out_features=128, bias=True)
          (linear_v): Linear(in_features=128, out_features=128, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=128, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=128, out_features=16, bias=True)
            (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=16, out_features=16, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=128, out_features=128, bias=False)
        (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): PointTransformerBlock(
        (linear1): Linear(in_features=128, out_features=128, bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=128, out_features=128, bias=True)
          (linear_k): Linear(in_features=128, out_features=128, bias=True)
          (linear_v): Linear(in_features=128, out_features=128, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=128, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=128, out_features=16, bias=True)
            (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=16, out_features=16, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=128, out_features=128, bias=False)
        (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): PointTransformerBlock(
        (linear1): Linear(in_features=128, out_features=128, bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=128, out_features=128, bias=True)
          (linear_k): Linear(in_features=128, out_features=128, bias=True)
          (linear_v): Linear(in_features=128, out_features=128, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=128, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=128, out_features=16, bias=True)
            (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=16, out_features=16, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=128, out_features=128, bias=False)
        (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (enc4): Sequential(
      (0): TransitionDown(
        (linear): Linear(in_features=131, out_features=256, bias=False)
        (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): PointTransformerBlock(
        (linear1): Linear(in_features=256, out_features=256, bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=256, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
            (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=32, out_features=32, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=256, out_features=256, bias=False)
        (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): PointTransformerBlock(
        (linear1): Linear(in_features=256, out_features=256, bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=256, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
            (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=32, out_features=32, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=256, out_features=256, bias=False)
        (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): PointTransformerBlock(
        (linear1): Linear(in_features=256, out_features=256, bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=256, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
            (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=32, out_features=32, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=256, out_features=256, bias=False)
        (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): PointTransformerBlock(
        (linear1): Linear(in_features=256, out_features=256, bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=256, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
            (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=32, out_features=32, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=256, out_features=256, bias=False)
        (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): PointTransformerBlock(
        (linear1): Linear(in_features=256, out_features=256, bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=256, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
            (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=32, out_features=32, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=256, out_features=256, bias=False)
        (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (enc5): Sequential(
      (0): TransitionDown(
        (linear): Linear(in_features=259, out_features=512, bias=False)
        (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
        (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): PointTransformerBlock(
        (linear1): Linear(in_features=512, out_features=512, bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=512, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=512, out_features=64, bias=True)
            (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=64, out_features=64, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=512, out_features=512, bias=False)
        (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): PointTransformerBlock(
        (linear1): Linear(in_features=512, out_features=512, bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=512, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=512, out_features=64, bias=True)
            (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=64, out_features=64, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=512, out_features=512, bias=False)
        (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (dec5): Sequential(
      (0): TransitionUp(
        (linear1): Sequential(
          (0): Linear(in_features=1024, out_features=512, bias=True)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (linear2): Sequential(
          (0): Linear(in_features=512, out_features=512, bias=True)
          (1): ReLU(inplace=True)
        )
      )
      (1): PointTransformerBlock(
        (linear1): Linear(in_features=512, out_features=512, bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=512, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=512, out_features=64, bias=True)
            (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=64, out_features=64, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=512, out_features=512, bias=False)
        (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (dec4): Sequential(
      (0): TransitionUp(
        (linear1): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (linear2): Sequential(
          (0): Linear(in_features=512, out_features=256, bias=True)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (1): PointTransformerBlock(
        (linear1): Linear(in_features=256, out_features=256, bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=256, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
            (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=32, out_features=32, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=256, out_features=256, bias=False)
        (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (dec3): Sequential(
      (0): TransitionUp(
        (linear1): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (linear2): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (1): PointTransformerBlock(
        (linear1): Linear(in_features=128, out_features=128, bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=128, out_features=128, bias=True)
          (linear_k): Linear(in_features=128, out_features=128, bias=True)
          (linear_v): Linear(in_features=128, out_features=128, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=128, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=128, out_features=16, bias=True)
            (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=16, out_features=16, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=128, out_features=128, bias=False)
        (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (dec2): Sequential(
      (0): TransitionUp(
        (linear1): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (linear2): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (1): PointTransformerBlock(
        (linear1): Linear(in_features=64, out_features=64, bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=64, out_features=64, bias=True)
          (linear_k): Linear(in_features=64, out_features=64, bias=True)
          (linear_v): Linear(in_features=64, out_features=64, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=64, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=64, out_features=8, bias=True)
            (3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=8, out_features=8, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=64, out_features=64, bias=False)
        (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (dec1): Sequential(
      (0): TransitionUp(
        (linear1): Sequential(
          (0): Linear(in_features=32, out_features=32, bias=True)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (linear2): Sequential(
          (0): Linear(in_features=64, out_features=32, bias=True)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (1): PointTransformerBlock(
        (linear1): Linear(in_features=32, out_features=32, bias=False)
        (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (transformer2): PointTransformerLayer(
          (linear_q): Linear(in_features=32, out_features=32, bias=True)
          (linear_k): Linear(in_features=32, out_features=32, bias=True)
          (linear_v): Linear(in_features=32, out_features=32, bias=True)
          (linear_p): Sequential(
            (0): Linear(in_features=3, out_features=3, bias=True)
            (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=3, out_features=32, bias=True)
          )
          (linear_w): Sequential(
            (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=32, out_features=4, bias=True)
            (3): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU(inplace=True)
            (5): Linear(in_features=4, out_features=4, bias=True)
          )
          (softmax): Softmax(dim=1)
        )
        (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (linear3): Linear(in_features=32, out_features=32, bias=False)
        (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (foldingnet1): Fold(
    (folding1): Sequential(
      (0): Conv1d(37, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
    (folding2): Sequential(
      (0): Conv1d(38, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
  )
  (foldingnet2): Fold(
    (folding1): Sequential(
      (0): Conv1d(69, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
    (folding2): Sequential(
      (0): Conv1d(70, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
  )
  (foldingnet3): Fold(
    (folding1): Sequential(
      (0): Conv1d(133, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
    (folding2): Sequential(
      (0): Conv1d(134, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
  )
  (foldingnet4): Fold(
    (folding1): Sequential(
      (0): Conv1d(261, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
    (folding2): Sequential(
      (0): Conv1d(262, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
  )
  (foldingnet5): Fold(
    (folding1): Sequential(
      (0): Conv1d(517, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
    (folding2): Sequential(
      (0): Conv1d(518, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
  )
  (m_foldingnet1): Fold(
    (folding1): Sequential(
      (0): Conv1d(37, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
    (folding2): Sequential(
      (0): Conv1d(38, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
  )
  (m_foldingnet2): Fold(
    (folding1): Sequential(
      (0): Conv1d(69, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
    (folding2): Sequential(
      (0): Conv1d(70, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
  )
  (m_foldingnet3): Fold(
    (folding1): Sequential(
      (0): Conv1d(133, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
    (folding2): Sequential(
      (0): Conv1d(134, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
  )
  (m_foldingnet4): Fold(
    (folding1): Sequential(
      (0): Conv1d(261, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
    (folding2): Sequential(
      (0): Conv1d(262, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
  )
  (m_foldingnet5): Fold(
    (folding1): Sequential(
      (0): Conv1d(517, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
    (folding2): Sequential(
      (0): Conv1d(518, 256, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
    )
  )
)
[2022-09-15 15:18:07,070 INFO train_PT-2.py line 253 1877698] train_data samples: '3060'
Loaded JIT 3D CUDA emd
Totally 204 samples in train set.
Loaded JIT 3D CUDA emd
Totally 204 samples in train set.
Loaded JIT 3D CUDA emd
Totally 204 samples in train set.
Jitting Chamfer 3D
Loaded JIT 3D CUDA chamfer distance
Loaded JIT 3D CUDA emd
Totally 204 samples in train set.
Jitting Chamfer 3D
Loaded JIT 3D CUDA chamfer distance
Jitting Chamfer 3D
Loaded JIT 3D CUDA chamfer distance
/home/xumingye/anaconda3/envs/PT/lib/python3.7/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
[2022-09-15 15:18:56,460 INFO train_PT-2.py line 411 1877698] Epoch: [1/50][10/191] Data 3.235 (1.538) Batch 6.576 (4.938) Remain 13:05:12 Loss 30.9772 Accuracy 0.0000.
[2022-09-15 15:19:33,076 INFO train_PT-2.py line 411 1877698] Epoch: [1/50][20/191] Data 1.178 (1.258) Batch 3.742 (4.300) Remain 11:22:58 Loss 28.5996 Accuracy 0.0000.
[2022-09-15 15:20:13,648 INFO train_PT-2.py line 411 1877698] Epoch: [1/50][30/191] Data 0.001 (1.133) Batch 4.083 (4.219) Remain 11:09:25 Loss 28.0995 Accuracy 0.0000.
[2022-09-15 15:20:51,072 INFO train_PT-2.py line 411 1877698] Epoch: [1/50][40/191] Data 0.001 (0.850) Batch 6.500 (4.100) Remain 10:49:50 Loss 25.6808 Accuracy 0.0000.
[2022-09-15 15:21:29,342 INFO train_PT-2.py line 411 1877698] Epoch: [1/50][50/191] Data 2.676 (0.862) Batch 5.133 (4.045) Remain 10:40:30 Loss 24.0794 Accuracy 0.0000.
[2022-09-15 15:22:07,776 INFO train_PT-2.py line 411 1877698] Epoch: [1/50][60/191] Data 0.409 (0.792) Batch 3.182 (4.012) Remain 10:34:30 Loss 21.4403 Accuracy 0.0000.
[2022-09-15 15:22:49,186 INFO train_PT-2.py line 411 1877698] Epoch: [1/50][70/191] Data 0.001 (0.797) Batch 2.494 (4.030) Remain 10:36:45 Loss 21.9121 Accuracy 0.0000.
[2022-09-15 15:23:28,275 INFO train_PT-2.py line 411 1877698] Epoch: [1/50][80/191] Data 0.001 (0.716) Batch 2.643 (4.015) Remain 10:33:41 Loss 20.1370 Accuracy 0.0000.
[2022-09-15 15:24:03,466 INFO train_PT-2.py line 411 1877698] Epoch: [1/50][90/191] Data 0.001 (0.637) Batch 2.749 (3.960) Remain 10:24:20 Loss 20.6401 Accuracy 0.0000.
[2022-09-15 15:24:39,431 INFO train_PT-2.py line 411 1877698] Epoch: [1/50][100/191] Data 0.001 (0.573) Batch 2.127 (3.924) Remain 10:17:57 Loss 18.9434 Accuracy 0.0000.
[2022-09-15 15:25:18,664 INFO train_PT-2.py line 411 1877698] Epoch: [1/50][110/191] Data 0.001 (0.574) Batch 2.716 (3.924) Remain 10:17:18 Loss 18.6186 Accuracy 0.0000.
[2022-09-15 15:25:55,935 INFO train_PT-2.py line 411 1877698] Epoch: [1/50][120/191] Data 0.001 (0.554) Batch 4.367 (3.907) Remain 10:14:04 Loss 18.8137 Accuracy 0.0000.
[2022-09-15 15:26:35,137 INFO train_PT-2.py line 411 1877698] Epoch: [1/50][130/191] Data 0.001 (0.553) Batch 4.222 (3.908) Remain 10:13:34 Loss 18.6253 Accuracy 0.0000.
[2022-09-15 15:27:13,648 INFO train_PT-2.py line 411 1877698] Epoch: [1/50][140/191] Data 0.215 (0.540) Batch 2.958 (3.904) Remain 10:12:17 Loss 18.9585 Accuracy 0.0000.
Jitting Chamfer 3D
Loaded JIT 3D CUDA chamfer distance
Loaded JIT 3D CUDA emd
Traceback (most recent call last):
  File "tool/train_PT-2.py", line 498, in <module>
    main()
  File "tool/train_PT-2.py", line 169, in main
    mp.spawn(main_worker, nprocs=args.ngpus_per_node, args=(args.ngpus_per_node, args))
  File "/home/xumingye/anaconda3/envs/PT/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/xumingye/anaconda3/envs/PT/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/home/xumingye/anaconda3/envs/PT/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 136, in join
    signal_name=name
torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGKILL
Loaded JIT 3D CUDA emd
Jitting Chamfer 3D
Loaded JIT 3D CUDA chamfer distance
Loaded JIT 3D CUDA emd
Loaded JIT 3D CUDA emd
