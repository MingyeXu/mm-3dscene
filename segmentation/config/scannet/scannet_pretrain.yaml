DATA:
  data_name: scannet
  data_root: dataset/scannet
  fea_dim: 6
  voxel_size: 0.02
  voxel_max: 120000
  loop: 6


TRAIN:
  arch: pointtransformer_seg_repro
  use_xyz: True
  sync_bn: False  # adopt sync_bn or not
  ignore_label: 255
  train_gpu: [4,5,6,7]
  workers: 1   # data loader workers
  batch_size: 8  # batch size for training
  batch_size_val: 4   # batch size for validation during training, memory and speed tradeoff
  base_lr: 0.001
  epochs: 50
  start_epoch: 0
  step_epoch: 30
  multiplier: 0.1
  momentum: 0.9
  weight_decay: 0.0001
  manual_seed: 7777
  print_freq: 10
  save_freq: 1
  save_path: exp/scannet/pretrain
  weight:  # path to initial weight (default: none)
  resume:  # path to latest checkpoint (default: none)
  evaluate: False  # evaluate on validation set, extra gpu memory needed and small batch_size_val is recommend
  eval_freq: 1 # evaluate on validation set, extra gpu memory needed and small batch_size_val is recommend
  # correlation_loss: True
  # correlation_loss_scale: 10.0
Distributed:
  dist_url: tcp://localhost:8888
  dist_backend: 'nccl'
  multiprocessing_distributed: True
  world_size: 1
  rank: 0


